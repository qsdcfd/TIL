{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuJDHHe8_5c0"
      },
      "source": [
        "### Topic Modeling using HDP and LDA\n",
        "\n",
        "- Text Processing\n",
        "- Generating dictionary of vocabulary\n",
        "- Mapping corpus using dictionary\n",
        "- Training the Topic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H3U8ij7OAHgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eac0526-ea82-4178-e2f2-c1cf89c68f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyLDAvis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vCvOlbtkA64Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7497fb4-99ed-4959-dba6-ada6a63d30ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "openjdk-8-jdk is already the newest version (8u342-b07-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy\n",
        "#시간이 좀 걸려요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMaIQUmSA9qW",
        "outputId": "4658f896-51b3-4750-c7b2-29ab6986f564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ],
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwE8OQpdBAFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d780990c-928b-41db-a427-257c9f3cfa50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py): started\n",
            "  Building wheel for mecab-python (setup.py): finished with status 'done'\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141808 sha256=a1b3f1be7966674760a7ef344d732e44c846c0d55d637c6a3feb6d648afe0bfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "  Attempting uninstall: mecab-python\n",
            "    Found existing installation: mecab-python 0.996-ko-0.9.2\n",
            "    Uninstalling mecab-python-0.996-ko-0.9.2:\n",
            "      Successfully uninstalled mecab-python-0.996-ko-0.9.2\n",
            "    Running setup.py install for mecab-python: started\n",
            "    Running setup.py install for mecab-python: finished with status 'done'\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\n",
            "  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996\n",
        "#시간이 좀 걸립니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5tqLjYXCPyj",
        "outputId": "4cb11f13-ad1e-438d-fa68-f3d1fb3e652d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "az2_W5pYBAHn"
      },
      "outputs": [],
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma, Komoran, Hannanum, Okt\n",
        "from konlpy.utils import pprint\n",
        "from konlpy.tag import Mecab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PdgK7Uum_31S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6877fb-f71f-4cbe-93b4-dc244884f9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import numpy as np\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from gensim import corpora, models\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import pyLDAvis.gensim_models\n",
        "#Import nltk stopwords and add custom stopwords that are likely to appear in news articles.\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend([\"mrs\",\"ms\",\"say\",\"he\",\"mr\",\"she\",\"they\",\"company\"])\n",
        "\n",
        "import os, re, operator, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "CipgDQosAUKc",
        "outputId": "6d1ff69e-981b-4b0d-de27-336fca58bc9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           publish_date                                article_source_link  \\\n",
              "article_id                                                                   \n",
              "1              2017/2/7  http://abcnews.go.com/Politics/pence-break-tie...   \n",
              "2              2017/2/7  http://abcnews.go.com/Politics/wireStory/melan...   \n",
              "3              2017/2/7  http://abcnews.go.com/Politics/wireStory/trump...   \n",
              "4              2017/2/7  http://abcnews.go.com/Politics/appeals-court-d...   \n",
              "5              2017/2/7  http://abcnews.go.com/US/23-states-winter-weat...   \n",
              "\n",
              "                                                        title subtitle  \\\n",
              "article_id                                                               \n",
              "1           Betsy DeVos Confirmed as Education Secretary, ...      NaN   \n",
              "2           Melania Trump Says White House Could Mean Mill...      NaN   \n",
              "3           As Trump Fears Fraud, GOP Eliminates Election ...      NaN   \n",
              "4           Appeals Court to Decide on Challenge to Trump'...      NaN   \n",
              "5           At Least 4 Tornadoes Reported in Southeast Lou...      NaN   \n",
              "\n",
              "                                                         text  \n",
              "article_id                                                     \n",
              "1           Michigan billionaire education activist Betsy ...  \n",
              "2           First lady Melania Trump has said little about...  \n",
              "3           A House committee voted on Tuesday to eliminat...  \n",
              "4           This afternoon, three federal judges from the ...  \n",
              "5           At least four tornadoes touched down in Louisi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9aa40a6-fd6b-4dbe-86c1-b26b4053deb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>article_source_link</th>\n",
              "      <th>title</th>\n",
              "      <th>subtitle</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>article_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017/2/7</td>\n",
              "      <td>http://abcnews.go.com/Politics/pence-break-tie...</td>\n",
              "      <td>Betsy DeVos Confirmed as Education Secretary, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michigan billionaire education activist Betsy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017/2/7</td>\n",
              "      <td>http://abcnews.go.com/Politics/wireStory/melan...</td>\n",
              "      <td>Melania Trump Says White House Could Mean Mill...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>First lady Melania Trump has said little about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017/2/7</td>\n",
              "      <td>http://abcnews.go.com/Politics/wireStory/trump...</td>\n",
              "      <td>As Trump Fears Fraud, GOP Eliminates Election ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A House committee voted on Tuesday to eliminat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017/2/7</td>\n",
              "      <td>http://abcnews.go.com/Politics/appeals-court-d...</td>\n",
              "      <td>Appeals Court to Decide on Challenge to Trump'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This afternoon, three federal judges from the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017/2/7</td>\n",
              "      <td>http://abcnews.go.com/US/23-states-winter-weat...</td>\n",
              "      <td>At Least 4 Tornadoes Reported in Southeast Lou...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>At least four tornadoes touched down in Louisi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9aa40a6-fd6b-4dbe-86c1-b26b4053deb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9aa40a6-fd6b-4dbe-86c1-b26b4053deb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9aa40a6-fd6b-4dbe-86c1-b26b4053deb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df=pd.read_csv(\"NewsArticles.csv\", encoding='unicode_escape',index_col=0)\n",
        "#drop all the unnamed columns\n",
        "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "La72Dg5P_444"
      },
      "outputs": [],
      "source": [
        "# before loading the language you have to download it first. Go to your command prompt and execute this statement and \n",
        "# restart the kernel:\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K0vrU2I7CXow"
      },
      "outputs": [],
      "source": [
        "data = df['text'].values.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3bcGtTBrCZg_"
      },
      "outputs": [],
      "source": [
        "#removing punctuations and others characters\n",
        "def preprocess(string):\n",
        "    return re.sub('[^\\w_\\s-]', ' ',str(string))\n",
        "\n",
        "data = list(map(preprocess,data))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q_1-IY8BCajW"
      },
      "outputs": [],
      "source": [
        "#data cleaning and lemmatization\n",
        "lemma_doc = []\n",
        "for datum in data:\n",
        "    sent = nlp(str(datum).lower())\n",
        "    text = []\n",
        "    for w in sent:\n",
        "        if not w.is_stop and not w.is_punct and not w.like_num and str(w) not in stop_words and (len(str(w)) > 4):\n",
        "            #adding the lematized version of the words\n",
        "            text.append(w.lemma_)\n",
        "    lemma_doc.append(text)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WH2xHAZMCbwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cd8909-cf4d-42d9-f3eb-03ec5afe984d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['michigan',\n",
              " 'billionaire',\n",
              " 'education',\n",
              " 'activist',\n",
              " 'betsy',\n",
              " 'devos',\n",
              " 'confirm',\n",
              " 'today',\n",
              " 'serve',\n",
              " 'secretary',\n",
              " 'education',\n",
              " 'president',\n",
              " 'trump',\n",
              " 'administration',\n",
              " 'president',\n",
              " 'pence',\n",
              " 'break',\n",
              " 'senate',\n",
              " 'senate',\n",
              " 'vote',\n",
              " 'devos',\n",
              " 'highly',\n",
              " 'contentious',\n",
              " 'nomination',\n",
              " 'afternoon',\n",
              " 'tally',\n",
              " 'split',\n",
              " 'evenly',\n",
              " 'require',\n",
              " 'penny',\n",
              " 'authority',\n",
              " 'president',\n",
              " 'upper',\n",
              " 'chamber',\n",
              " 'congress',\n",
              " 'break',\n",
              " 'impasse',\n",
              " 'president',\n",
              " 'break',\n",
              " 'confirm',\n",
              " 'cabinet',\n",
              " 'nominee',\n",
              " 'penny',\n",
              " 'count',\n",
              " 'vote',\n",
              " 'render',\n",
              " 'tally',\n",
              " 'democrats',\n",
              " 'stage',\n",
              " 'marathon',\n",
              " 'speech',\n",
              " 'lawmaker',\n",
              " 'take',\n",
              " 'floor',\n",
              " 'additional',\n",
              " 'republican',\n",
              " 'devos',\n",
              " 'block',\n",
              " 'confirmation',\n",
              " 'imagine',\n",
              " 'bad',\n",
              " 'choice',\n",
              " 'elizabeth',\n",
              " 'warren',\n",
              " 'letter',\n",
              " 'constituent',\n",
              " 'urge',\n",
              " 'devos',\n",
              " 'stir',\n",
              " 'vehement',\n",
              " 'opposition',\n",
              " 'teacher',\n",
              " 'union',\n",
              " 'senate',\n",
              " 'democrats',\n",
              " 'cite',\n",
              " 'concern',\n",
              " 'support',\n",
              " 'school',\n",
              " 'voucher',\n",
              " 'critic',\n",
              " 'believe',\n",
              " 'weaken',\n",
              " 'public',\n",
              " 'school',\n",
              " 'experience',\n",
              " 'attend',\n",
              " 'work',\n",
              " 'public',\n",
              " 'education',\n",
              " 'system',\n",
              " 'cite',\n",
              " 'familiarity',\n",
              " 'landmark',\n",
              " 'protect',\n",
              " 'education',\n",
              " 'need',\n",
              " 'disabled',\n",
              " 'child',\n",
              " '     ',\n",
              " 'pan',\n",
              " 'gaffe',\n",
              " 'confirmation',\n",
              " 'hearing',\n",
              " 'hedge',\n",
              " 'answer',\n",
              " 'school',\n",
              " 'say',\n",
              " 'need',\n",
              " 'state',\n",
              " 'wyoming',\n",
              " 'defend',\n",
              " 'potential',\n",
              " 'grizzly',\n",
              " 'devos',\n",
              " 'nomination',\n",
              " 'average',\n",
              " 'negative',\n",
              " 'reaction',\n",
              " 'public',\n",
              " 'voter',\n",
              " 'flood',\n",
              " 'senate',\n",
              " 'phone',\n",
              " 'line',\n",
              " 'email',\n",
              " 'account',\n",
              " 'recent',\n",
              " 'week',\n",
              " 'chris',\n",
              " 'hollen',\n",
              " 'office',\n",
              " 'receive',\n",
              " 'call',\n",
              " 'devos',\n",
              " 'addition',\n",
              " 'entire',\n",
              " 'democratic',\n",
              " 'caucus',\n",
              " 'moderate',\n",
              " 'republicans',\n",
              " 'susan',\n",
              " 'collins',\n",
              " 'maine',\n",
              " 'murkowski',\n",
              " 'alaska',\n",
              " 'announce',\n",
              " 'support',\n",
              " 'devos',\n",
              " 'speech',\n",
              " 'announce',\n",
              " 'opposition',\n",
              " 'collin',\n",
              " 'devos',\n",
              " 'focus',\n",
              " 'charter',\n",
              " 'voucher',\n",
              " 'raise',\n",
              " 'question',\n",
              " 'fully',\n",
              " 'appreciate',\n",
              " 'secretary',\n",
              " 'education',\n",
              " 'primary',\n",
              " 'focus',\n",
              " 'help',\n",
              " 'state',\n",
              " 'community',\n",
              " 'parent',\n",
              " 'teacher',\n",
              " 'school',\n",
              " 'board',\n",
              " 'member',\n",
              " 'administrator',\n",
              " 'strengthen',\n",
              " 'public',\n",
              " 'school',\n",
              " 'confirmation',\n",
              " 'senate',\n",
              " 'health',\n",
              " 'education',\n",
              " 'labor',\n",
              " 'pension',\n",
              " 'committee',\n",
              " 'vote',\n",
              " 'party',\n",
              " 'line',\n",
              " 'refer',\n",
              " 'devos',\n",
              " 'nomination',\n",
              " 'senate',\n",
              " 'morgan',\n",
              " 'winsor',\n",
              " 'contribute',\n",
              " 'report']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "lemma_doc[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3A2NauQQCfEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4757a6f-48a3-492c-ce24-1af992dabc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['michigan', 'billionaire', 'education', 'activist', 'betsy_devos', 'confirm', 'today', 'serve', 'secretary', 'education', 'president', 'trump', 'administration', 'president', 'pence', 'break', 'senate', 'senate', 'vote', 'devos', 'highly', 'contentious', 'nomination', 'afternoon', 'tally', 'split', 'evenly', 'require', 'penny', 'authority', 'president', 'upper', 'chamber', 'congress', 'break', 'impasse', 'president', 'break', 'confirm', 'cabinet_nominee', 'penny', 'count', 'vote', 'render', 'tally', 'democrats', 'stage', 'marathon', 'speech', 'lawmaker', 'take', 'floor', 'additional', 'republican', 'devos', 'block', 'confirmation', 'imagine', 'bad', 'choice', 'elizabeth_warren', 'letter', 'constituent', 'urge', 'devos', 'stir', 'vehement', 'opposition', 'teacher', 'union', 'senate', 'democrats', 'cite', 'concern', 'support', 'school', 'voucher', 'critic', 'believe', 'weaken', 'public', 'school', 'experience', 'attend', 'work', 'public', 'education', 'system', 'cite', 'familiarity', 'landmark', 'protect', 'education', 'need', 'disabled', 'child', '     ', 'pan', 'gaffe', 'confirmation_hearing', 'hedge', 'answer', 'school', 'say', 'need', 'state', 'wyoming', 'defend', 'potential', 'grizzly', 'devos', 'nomination', 'average', 'negative', 'reaction', 'public', 'voter', 'flood', 'senate', 'phone', 'line', 'email_account', 'recent', 'week', 'chris', 'hollen', 'office', 'receive', 'call', 'devos', 'addition', 'entire', 'democratic', 'caucus', 'moderate', 'republicans', 'susan', 'collins', 'maine', 'murkowski', 'alaska', 'announce', 'support', 'devos', 'speech', 'announce', 'opposition', 'collin', 'devos', 'focus', 'charter', 'voucher', 'raise', 'question', 'fully', 'appreciate', 'secretary', 'education', 'primary', 'focus', 'help', 'state', 'community', 'parent', 'teacher', 'school', 'board', 'member', 'administrator', 'strengthen', 'public', 'school', 'confirmation', 'senate', 'health', 'education', 'labor', 'pension', 'committee', 'vote', 'party', 'line', 'refer', 'devos', 'nomination', 'senate', 'morgan', 'winsor', 'contribute', 'report']\n"
          ]
        }
      ],
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(lemma_doc, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[lemma_doc], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[lemma_doc[0]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI5xaDOeCfNB"
      },
      "source": [
        "**Create the Dictionary and Corpus needed for Topic Modeling**\n",
        "\n",
        "- Word to IDs mapping\n",
        "- Bag of words of each document\n",
        "- corpus (cluster of Bag of words of all the documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gcfr3yWGCitG"
      },
      "outputs": [],
      "source": [
        "#Creates Word to IDs mapping\n",
        "word2id = corpora.Dictionary(lemma_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6jJGWx2BCk_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08430df-c07f-4fa5-ffae-e3ead9c10c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus sample\n",
            "Word 0 :        || Number of occurences: 1\n",
            "Word 1 : account  || Number of occurences: 1\n",
            "Word 2 : activist  || Number of occurences: 1\n",
            "Word 3 : addition  || Number of occurences: 1\n",
            "Word 4 : additional  || Number of occurences: 1\n",
            "Word 5 : administration  || Number of occurences: 1\n",
            "Word 6 : administrator  || Number of occurences: 1\n",
            "Word 7 : afternoon  || Number of occurences: 1\n",
            "Word 8 : alaska  || Number of occurences: 1\n",
            "Word 9 : announce  || Number of occurences: 2\n",
            "Word 10 : answer  || Number of occurences: 1\n",
            "Word 11 : appreciate  || Number of occurences: 1\n",
            "Word 12 : attend  || Number of occurences: 1\n",
            "Word 13 : authority  || Number of occurences: 1\n",
            "Word 14 : average  || Number of occurences: 1\n",
            "Word 15 : bad  || Number of occurences: 1\n",
            "Word 16 : believe  || Number of occurences: 1\n",
            "Word 17 : betsy  || Number of occurences: 1\n",
            "Word 18 : billionaire  || Number of occurences: 1\n",
            "Word 19 : block  || Number of occurences: 1\n",
            "Word 20 : board  || Number of occurences: 1\n",
            "Word 21 : break  || Number of occurences: 3\n",
            "Word 22 : cabinet  || Number of occurences: 1\n",
            "Word 23 : call  || Number of occurences: 1\n",
            "Word 24 : caucus  || Number of occurences: 1\n",
            "Word 25 : chamber  || Number of occurences: 1\n",
            "Word 26 : charter  || Number of occurences: 1\n",
            "Word 27 : child  || Number of occurences: 1\n",
            "Word 28 : choice  || Number of occurences: 1\n",
            "Word 29 : chris  || Number of occurences: 1\n",
            "Word 30 : cite  || Number of occurences: 2\n",
            "Word 31 : collin  || Number of occurences: 1\n",
            "Word 32 : collins  || Number of occurences: 1\n",
            "Word 33 : committee  || Number of occurences: 1\n",
            "Word 34 : community  || Number of occurences: 1\n",
            "Word 35 : concern  || Number of occurences: 1\n",
            "Word 36 : confirm  || Number of occurences: 2\n",
            "Word 37 : confirmation  || Number of occurences: 3\n",
            "Word 38 : congress  || Number of occurences: 1\n",
            "Word 39 : constituent  || Number of occurences: 1\n",
            "Word 40 : contentious  || Number of occurences: 1\n",
            "Word 41 : contribute  || Number of occurences: 1\n",
            "Word 42 : count  || Number of occurences: 1\n",
            "Word 43 : critic  || Number of occurences: 1\n",
            "Word 44 : defend  || Number of occurences: 1\n",
            "Word 45 : democratic  || Number of occurences: 1\n",
            "Word 46 : democrats  || Number of occurences: 2\n",
            "Word 47 : devos  || Number of occurences: 9\n",
            "Word 48 : disabled  || Number of occurences: 1\n",
            "Word 49 : education  || Number of occurences: 6\n",
            "Word 50 : elizabeth  || Number of occurences: 1\n",
            "Word 51 : email  || Number of occurences: 1\n",
            "Word 52 : entire  || Number of occurences: 1\n",
            "Word 53 : evenly  || Number of occurences: 1\n",
            "Word 54 : experience  || Number of occurences: 1\n",
            "Word 55 : familiarity  || Number of occurences: 1\n",
            "Word 56 : flood  || Number of occurences: 1\n",
            "Word 57 : floor  || Number of occurences: 1\n",
            "Word 58 : focus  || Number of occurences: 2\n",
            "Word 59 : fully  || Number of occurences: 1\n",
            "Word 60 : gaffe  || Number of occurences: 1\n",
            "Word 61 : grizzly  || Number of occurences: 1\n",
            "Word 62 : health  || Number of occurences: 1\n",
            "Word 63 : hearing  || Number of occurences: 1\n",
            "Word 64 : hedge  || Number of occurences: 1\n",
            "Word 65 : help  || Number of occurences: 1\n",
            "Word 66 : highly  || Number of occurences: 1\n",
            "Word 67 : hollen  || Number of occurences: 1\n",
            "Word 68 : imagine  || Number of occurences: 1\n",
            "Word 69 : impasse  || Number of occurences: 1\n",
            "Word 70 : labor  || Number of occurences: 1\n",
            "Word 71 : landmark  || Number of occurences: 1\n",
            "Word 72 : lawmaker  || Number of occurences: 1\n",
            "Word 73 : letter  || Number of occurences: 1\n",
            "Word 74 : line  || Number of occurences: 2\n",
            "Word 75 : maine  || Number of occurences: 1\n",
            "Word 76 : marathon  || Number of occurences: 1\n",
            "Word 77 : member  || Number of occurences: 1\n",
            "Word 78 : michigan  || Number of occurences: 1\n",
            "Word 79 : moderate  || Number of occurences: 1\n",
            "Word 80 : morgan  || Number of occurences: 1\n",
            "Word 81 : murkowski  || Number of occurences: 1\n",
            "Word 82 : need  || Number of occurences: 2\n",
            "Word 83 : negative  || Number of occurences: 1\n",
            "Word 84 : nomination  || Number of occurences: 3\n",
            "Word 85 : nominee  || Number of occurences: 1\n",
            "Word 86 : office  || Number of occurences: 1\n",
            "Word 87 : opposition  || Number of occurences: 2\n",
            "Word 88 : pan  || Number of occurences: 1\n",
            "Word 89 : parent  || Number of occurences: 1\n",
            "Word 90 : party  || Number of occurences: 1\n",
            "Word 91 : pence  || Number of occurences: 1\n",
            "Word 92 : penny  || Number of occurences: 2\n",
            "Word 93 : pension  || Number of occurences: 1\n",
            "Word 94 : phone  || Number of occurences: 1\n",
            "Word 95 : potential  || Number of occurences: 1\n",
            "Word 96 : president  || Number of occurences: 4\n",
            "Word 97 : primary  || Number of occurences: 1\n",
            "Word 98 : protect  || Number of occurences: 1\n",
            "Word 99 : public  || Number of occurences: 4\n",
            "Word 100 : question  || Number of occurences: 1\n",
            "Word 101 : raise  || Number of occurences: 1\n",
            "Word 102 : reaction  || Number of occurences: 1\n",
            "Word 103 : receive  || Number of occurences: 1\n",
            "Word 104 : recent  || Number of occurences: 1\n",
            "Word 105 : refer  || Number of occurences: 1\n",
            "Word 106 : render  || Number of occurences: 1\n",
            "Word 107 : report  || Number of occurences: 1\n",
            "Word 108 : republican  || Number of occurences: 1\n",
            "Word 109 : republicans  || Number of occurences: 1\n",
            "Word 110 : require  || Number of occurences: 1\n",
            "Word 111 : say  || Number of occurences: 1\n",
            "Word 112 : school  || Number of occurences: 5\n",
            "Word 113 : secretary  || Number of occurences: 2\n",
            "Word 114 : senate  || Number of occurences: 6\n",
            "Word 115 : serve  || Number of occurences: 1\n",
            "Word 116 : speech  || Number of occurences: 2\n",
            "Word 117 : split  || Number of occurences: 1\n",
            "Word 118 : stage  || Number of occurences: 1\n",
            "Word 119 : state  || Number of occurences: 2\n",
            "Word 120 : stir  || Number of occurences: 1\n",
            "Word 121 : strengthen  || Number of occurences: 1\n",
            "Word 122 : support  || Number of occurences: 2\n",
            "Word 123 : susan  || Number of occurences: 1\n",
            "Word 124 : system  || Number of occurences: 1\n",
            "Word 125 : take  || Number of occurences: 1\n",
            "Word 126 : tally  || Number of occurences: 2\n",
            "Word 127 : teacher  || Number of occurences: 2\n",
            "Word 128 : today  || Number of occurences: 1\n",
            "Word 129 : trump  || Number of occurences: 1\n",
            "Word 130 : union  || Number of occurences: 1\n",
            "Word 131 : upper  || Number of occurences: 1\n",
            "Word 132 : urge  || Number of occurences: 1\n",
            "Word 133 : vehement  || Number of occurences: 1\n",
            "Word 134 : vote  || Number of occurences: 3\n",
            "Word 135 : voter  || Number of occurences: 1\n",
            "Word 136 : voucher  || Number of occurences: 2\n",
            "Word 137 : warren  || Number of occurences: 1\n",
            "Word 138 : weaken  || Number of occurences: 1\n",
            "Word 139 : week  || Number of occurences: 1\n",
            "Word 140 : winsor  || Number of occurences: 1\n",
            "Word 141 : work  || Number of occurences: 1\n",
            "Word 142 : wyoming  || Number of occurences: 1\n"
          ]
        }
      ],
      "source": [
        "# Creates bag of words and a corpus\n",
        "documents = lemma_doc\n",
        "corpus = [word2id.doc2bow(doc) for doc in documents]\n",
        "\n",
        "print('Corpus sample')\n",
        "sample = corpus[0]\n",
        "for i in range(len(sample)):\n",
        "    print('Word', sample[i][0], ':', word2id[sample[i][0]], ' || Number of occurences:', sample[i][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se3vsPPGCqO-"
      },
      "source": [
        "Hierarchical Dirichlet Processing\n",
        "\n",
        "This is kind of an unsupervised technique (Topic modeling is a unsupervised technique. Here the context is we don't decide the # of topics. \n",
        "\n",
        "In concept this is similar to Hierarchical cluster as don't choose the number of cluster before hand) as the model will identify the number of topics. Let's see what it will produce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7cJtDk5_CqZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7ef0f1-070d-4210-ce58-36e55bc040b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n",
            "WARNING:gensim.models.hdpmodel:likelihood is decreasing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.008*trump + 0.006*people + 0.005*president + 0.004*country + 0.004*government + 0.004*state + 0.004*china + 0.003*house + 0.003*report + 0.003*include')\n",
            "(1, '0.007*trump + 0.006*people + 0.005*country + 0.005*president + 0.004*china + 0.004*government + 0.003*state + 0.003*report + 0.003*house + 0.003*year')\n",
            "(2, '0.010*china + 0.004*chinese + 0.003*percent + 0.003*market + 0.003*country + 0.003*world + 0.002*government + 0.002*chestnut + 0.002*european + 0.002*growth')\n",
            "(3, '0.006*china + 0.004*happen + 0.004*cover + 0.004*people + 0.003*attack + 0.003*trump + 0.003*president + 0.002*country + 0.002*police + 0.002*house')\n",
            "(4, '0.003*china + 0.002*people + 0.002*child + 0.002*waste + 0.002*court + 0.002*year + 0.002*country + 0.002*family + 0.002*service + 0.002*government')\n",
            "(5, '0.004*china + 0.002*chinese + 0.002*trump + 0.002*court + 0.002*government + 0.002*country + 0.002*people + 0.002*state + 0.001*domestic + 0.001*percent')\n",
            "(6, '0.003*china + 0.002*country + 0.002*people + 0.002*afghanistan + 0.002*business + 0.001*region + 0.001*company + 0.001*honeywell + 0.001*crisis + 0.001*chinese')\n",
            "(7, '0.002*tequila + 0.002*marsh + 0.002*think + 0.001*people + 0.001*chang + 0.001*agave + 0.001*water + 0.001*border + 0.001*thing + 0.001*plant')\n",
            "(8, '0.002*search + 0.001*china + 0.001*coral + 0.001*great + 0.001*family + 0.001*people + 0.001*scientist + 0.001*region + 0.001*science + 0.001*voice')\n",
            "(9, '0.004*president + 0.002*sugar + 0.002*trump + 0.002*government + 0.002*court + 0.002*chinese + 0.002*monster + 0.002*film + 0.001*judge + 0.001*sweetener')\n",
            "(10, '0.003*report + 0.003*russian + 0.001*court + 0.001*torture + 0.001*attack + 0.001*brady + 0.001*provisional + 0.001*suspension + 0.001*international + 0.001*athlete')\n",
            "(11, '0.003*china + 0.003*school + 0.002*country + 0.002*chinese + 0.002*lloyd + 0.002*market + 0.002*company + 0.002*people + 0.001*private + 0.001*learn')\n",
            "(12, '0.003*china + 0.002*trump + 0.002*puzder + 0.001*investment + 0.001*senate + 0.001*engle + 0.001*financial + 0.001*president + 0.001*work + 0.001*devos')\n",
            "(13, '0.005*chinese + 0.004*brand + 0.004*china + 0.002*market + 0.002*foreign + 0.002*consumer + 0.002*maldive + 0.001*investment + 0.001*government + 0.001*investor')\n",
            "(14, '0.003*china + 0.001*president + 0.001*chinese + 0.001*trump + 0.001*climate + 0.001*country + 0.001*world + 0.001*russian + 0.001*russia + 0.001*international')\n",
            "(15, '0.003*market + 0.003*china + 0.002*investment + 0.002*asset + 0.002*overseas + 0.002*chinese + 0.002*percent + 0.001*invest + 0.001*nuclear + 0.001*arthena')\n",
            "(16, '0.003*china + 0.002*people + 0.002*illustrator + 0.002*harley + 0.002*illustration + 0.002*year + 0.002*davidson + 0.002*picture + 0.002*patient + 0.001*steel')\n",
            "(17, '0.002*china + 0.001*indigenous + 0.001*woman + 0.001*panda + 0.001*chinese + 0.001*roseonly + 0.001*year + 0.001*daily + 0.001*month + 0.001*vegetable')\n",
            "(18, '0.003*solar + 0.002*term + 0.001*queen + 0.001*china + 0.001*child + 0.001*chinese + 0.001*base + 0.001*perovskite + 0.001*winter + 0.001*people')\n",
            "(19, '0.002*tsingtao + 0.001*government + 0.001*science + 0.001*ivory + 0.001*germany + 0.001*china + 0.001*people + 0.001*migrant + 0.001*scientist + 0.001*market')\n"
          ]
        }
      ],
      "source": [
        "hdp = models.HdpModel(corpus,word2id)\n",
        "hdp_topics = hdp.print_topics()\n",
        "for topic in hdp_topics:\n",
        "    print(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wn-IAMdVCu1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a95574-099f-4f02-a031-ccae22dd516e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HDP model created: 20 Topics\n"
          ]
        }
      ],
      "source": [
        "print('HDP model created: '+str(len(hdp_topics))+' Topics')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qk1Xys-C1ca"
      },
      "source": [
        "## Latent Dirichlet Allocation Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "q7mp28naC2B9"
      },
      "outputs": [],
      "source": [
        "lda_model = LdaModel(corpus=corpus, id2word=word2id, num_topics=5, random_state=42, update_every=1, chunksize=100, \n",
        "                     passes=10, alpha='auto', per_word_topics=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0CECQCrAC4bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c984f56f-7410-4614-83a9-44b1544e7f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f7ff03a5250>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#Article - Topic Distribution for first Article\n",
        "def get_article_topic_distribution(article):\n",
        "    return lda.get_document_topics(article)\n",
        "#Returns a list containing a list of tuple\n",
        "#Each inner list corresponds to an article and each tuple refers to topicID and its corresponding probability  \n",
        "map(get_article_topic_distribution, corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xNg1xrKgC5c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8535e1b7-b460-4ed8-dcd0-9d25193ef4c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.020*\"trump\" + 0.012*\"president\" + 0.011*\"house\" + 0.007*\"committee\" + 0.006*\"state\" + 0.006*\"government\" + 0.006*\"white\" + 0.005*\"party\" + 0.005*\"election\" + 0.005*\"campaign\"'),\n",
              " (1,\n",
              "  '0.012*\"russian\" + 0.012*\"russia\" + 0.011*\"country\" + 0.009*\"north\" + 0.009*\"government\" + 0.008*\"force\" + 0.007*\"korea\" + 0.006*\"military\" + 0.006*\"state\" + 0.006*\"group\"'),\n",
              " (2,\n",
              "  '0.010*\"china\" + 0.009*\"percent\" + 0.006*\"country\" + 0.006*\"business\" + 0.006*\"market\" + 0.005*\"trade\" + 0.004*\"company\" + 0.004*\"economic\" + 0.004*\"european\" + 0.004*\"project\"'),\n",
              " (3,\n",
              "  '0.015*\"police\" + 0.010*\"garda\" + 0.007*\"people\" + 0.007*\"court\" + 0.006*\"arrest\" + 0.006*\"authority\" + 0.006*\"officer\" + 0.006*\"report\" + 0.006*\"death\" + 0.005*\"service\"'),\n",
              " (4,\n",
              "  '0.010*\"woman\" + 0.010*\"people\" + 0.007*\"family\" + 0.006*\"child\" + 0.005*\"school\" + 0.005*\"young\" + 0.004*\"year\" + 0.004*\"friend\" + 0.004*\"think\" + 0.004*\"learn\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "lda_model.print_topics()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlKb6WnC74I"
      },
      "source": [
        "**How to interpret this?**\n",
        "\n",
        "The top 10 keywords that contribute to the topic are showcased with their respective weight.\n",
        "\n",
        "Let's try to interpret the 5 topics:\n",
        "\n",
        "Topic 1: key words like \"Russia\", \"Country\", \"Government\", \"Minister\" suggest Politics in Russia\n",
        "\n",
        "Topic 2: key words like \"China\", \"Brexit\",\"Trade\", \"Business\", \n",
        "\"Market\" suggest Inter country trade news\n",
        "\n",
        "Topic 3: key words like \"Player\",\"Sport\",\"World\" suggest Sports news (football)\n",
        "\n",
        "Topic 4: key words like \"People\",\"Woman\",\"Police\", \"Family,\"Child\" suggest Domestic news\n",
        "\n",
        "Topic 5: key words like \"Trump\", \"State\", \"White\", \"Committee\" suggest Polictics in USA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QAmnUF1DDOt"
      },
      "source": [
        "### Compute Model Perplexity and Coherence Score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6ja5YRzrDB7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2e3fb5-e843-4ab6-8a3e-17ae8b3e0d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -8.408782266100435\n",
            "\n",
            "Coherence Score:  0.47351504028371866\n"
          ]
        }
      ],
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = models.CoherenceModel(model=lda_model, texts=lemma_doc, dictionary=word2id, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ26gn8MDHxE"
      },
      "source": [
        "Coherence measures the relative distance between words within a topic.\n",
        "\n",
        "There are two major types C_V typically 0 < x < 1 and uMass -14 < x < 14. \n",
        "\n",
        "Coherence score of 0.4 is low. I want to explore what would have been the ideal number of topics. Will explore the elbow method below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aIvlterrDH7-"
      },
      "outputs": [],
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, update_every=1, chunksize=100, \n",
        "                     passes=10, alpha='auto', per_word_topics=True)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = models.CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCZEK543DOn2"
      },
      "outputs": [],
      "source": [
        "#Use this to get the graph of optimal # of topics\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=word2id, corpus=corpus, texts=lemma_doc, start=2, limit=100, step=10)\n",
        "# Show graph\n",
        "import matplotlib.pyplot as plt\n",
        "limit=100; start=2; step=10;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqQKj84lDQIs"
      },
      "source": [
        "You can decide on the number of topics based on this analysis. \n",
        "\n",
        "Note that the Customization used for 5 topic model (lda_model) and the optimization models is difference therefore the Coherence score for 5 topics LDA model differ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rKVXnz7DUCu"
      },
      "source": [
        "### Vizualize the topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nWR6sLQDR0s"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.gensim.prepare(lda_model,corpus,word2id)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlGrJufRAMpLOFgcTtFH2m"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}