{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BeautifulSoup를 이용한 웹 데이터 스크래핑",
      "provenance": [],
      "authorship_tag": "ABX9TyOvaVIGZd4dOicsGER+Rsr+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### BeautifulSoup을 활용한 웹 스크래핑\n",
        "\n",
        "\n",
        "\n",
        "BeautifulSoup는 아주 강력한 라이브러리로 urllib과 더불어 사용하면 다음과 같이 원하는 웹 페이지에 존재하는 모든 링크의 URL을 출력할 수 있습니다.\n",
        "\n",
        "왜냐하면, 이것은 웹페이지에서 일어날 수 있는 다양한 문제들에 대해서 해결책을 모아놓은 것입니다.\n",
        "\n",
        "\n",
        "```\n",
        "import urllib.request, urllib.parse, urllib.error\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = input('Enter - ') #https://pypi.python.org/pypi/beautifulsoup4\n",
        "html = urllib.request.urlopen(url).read()\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Retrieve all of the anchor tags\n",
        "tags = soup('a')\n",
        "for tag in tags:\n",
        "    print(tag.get('href', None))\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "VWmDS_WEUqMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NTwGpy6_UqX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}