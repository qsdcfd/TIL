{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hadoop",
      "provenance": [],
      "authorship_tag": "ABX9TyPOVfU8n1HqbXJhzbWSZNOx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 하둡\n",
        "\n",
        "**출현 배경**\n",
        "\n",
        "모든 데이터 대상으로 하는 검색 엔진, 제공 필요는 하지만 그 당시의 저장 체계/파일 체계에서는 무리가 있었습니다.\n",
        "\n",
        "왜냐하면, 기존 데이터베이스/ 데이터 웨어하우스의 구조적 한계 때문입니다.\n",
        "\n",
        "그래서, 구글이 하둡이라는 대량 데이터 저장 및 처리 가능한 미들웨어를 자체 개발하게 됩니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**정의**\n",
        "\n",
        "하둡은 여러 컴퓨터로 구성된 클러스터를 이용해서 방대한 양의 데이터를 처리하는 병렬 분산 처리 프레임워크입니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**특징**\n",
        "\n",
        "엔진 형태로 되어 있는 미들웨어와 소프트웨어 개발 프레임 워크로 구성되어 있구요, 또한 방대한 양의 데이터를 분산 처리 할 수 있는 솔루션 입니다.\n",
        "\n",
        "\n",
        "또한 즉시 응답해야 하는 트랜잭션 처리보다는 데이터를 모은 후에 처리하여서 작업을 완료해야 응답해주는 방식으로 설계되었습니다.\n",
        "\n",
        "이에 어느 정도의 시간이 소요되는 방대한 양의 데이터 처리에 적합하다고 할 수 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 하둡의 코어 프로젝트\n",
        "\n",
        "**HDFS: 분산 데이터 저장**\n",
        "\n",
        "*정의\n",
        "\n",
        "대용량 파일에 높은 처리량으로 접근할 수 있도록 설계된 분산 파일 시스템입니다.\n",
        "\n",
        "일반적인 파일 시스템으로 말하자면 리눅스의 ext4나 XFS 등을 들 수 있기는 하지만, 이들은 한 대의 서버 상에서 파일을 관리하기 위한 것입니다.\n",
        "\n",
        "분산 파일 시스템은 복수의 서버에서 규모가 큰 하나의 파일 시스템을 제공하는 구조입니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "*편리성\n",
        "\n",
        "- 투과성\n",
        "\n",
        "*클라이언트 관점\n",
        "\n",
        "투과성은 클라이언트 관점에서는 파일 시스템의 내부에서 복수의 서버가 동작하고 있다는 것을 고려할 필요 없이,\n",
        "\n",
        "ext4 같은 로컬 파일 시스템을 다루듯이 투과적으로 접근할 수 있다는 특징이 있습니다.\n",
        "\n",
        "*사용자 관점\n",
        "\n",
        "사용자는 파일이 어떻게 블록으로 분할되어 있는지 의식할 필요가 없습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "- 확장성\n",
        "\n",
        "HDFS는 슬레이브 서버 데이터노드 대수를 늘려서, 용량과 기본적인 I/O 성능을 향상시킬 수 있구, 디스크 용량이 부족하면 서버를 추가하기만 하면 됩니다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "*신뢰성\n",
        "\n",
        "![](https://images.velog.io/images/qsdcfd/post/cca1f40b-5811-42c4-922e-c5f869b8965e/image.png)\n",
        "\n",
        "HDFS는 파일을 복수의 서버에 분할 배치하지만 하나의 파일을 복수의 블록으로 분할하고, 각각의 블록을 복수의 서버에 다중으로 기록하는 리플리케이션 기능을 가지고 있고 기본 설정에서는 각 블록이 세 개의 서버에 다중으로 저장됩니다.\n",
        "\n",
        "따라서 하나의 서버가 고장 나서 블록에 접근할 수 없게 되더라도 다른 서버에 동일한 블록이 존재하기 때문에 분산 파일 시스템 전체적으로 데이터 소실 위험이 낮아집니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "*접근 제한 패턴\n",
        "\n",
        "![](https://images.velog.io/images/qsdcfd/post/9af4e1c3-8228-48f8-a82f-bd246fd85dcb/image.png)\n",
        "\n",
        "HDFS에서는 높은 스루풋을 실현하기 위해서 데이터 접근 패턴을 제한하고 있습니다.\n",
        "\n",
        "예를 들면, 기본적으로 연속적 스트림 읽기를 전제로 하고 있구요, 랜덤 읽기 방식은 고려하지 않습니다.\n",
        "\n",
        "HDFS에서 데이터 기록은 한 번만 이루어지구요, 그 이후는 읽기 처리만 가능하고 데이터 변경은 불가능합니다.\n",
        "\n",
        "일반적인 파일 시스템 상에서 데이터를 다루는 것과는 많은 차이가 있어서 HDFS를 사용할 때는 이러한 제약사항을 충분히 고려해야 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**MapReduce: 분석 데이터 처리**\n",
        "\n",
        "*정의\n",
        "\n",
        "![](https://images.velog.io/images/qsdcfd/post/6f0097b0-9dcb-44b5-962c-4f4416957f11/image.png)\n",
        "\n",
        "MapReduce는 대규모 데이터 집합을 처리하기 위한 프로그래밍 모델이구요, 처리를 병렬로 실행하기 위해서 하나의 잡을 독립된 태스크로 나누어서 실행합니다.\n",
        "\n",
        "\n",
        "MapReduce는 크게 맵처리와 리듀스처리라고 불리는 두 단계로 구성이 되고\n",
        "맵처리는 주로 입력 파일을 한 줄씩 읽어서 필터링 등의 처리를 하고, 리듀스 처리는 데이터 집약을 맡습니다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 맵리듀스의 분산처리 구조 이용\n",
        "\n",
        "![](https://images.velog.io/images/qsdcfd/post/ff04b824-df30-4a90-b51d-6dac4a065410/image.png)\n",
        "\n",
        "맵리듀스는 하나의 큰 데이터를 여러 개의 조각으로 나누어 처리하는 맵단계와 처리된 결과를 하나로 모아서 취합한 후 결과를 도출해 내는 리듀스 단계로 구성되어 있습니다.\n",
        "\n",
        "![](https://images.velog.io/images/qsdcfd/post/123850a5-d051-499e-983c-eb037ae0d593/image.png)\n",
        "\n",
        "이러한 맵리듀스를 수행하려면 입력 데이터를 저장하고, 이 데이터를 일정조각으로 나누어서 저장합니다.\n",
        "\n",
        "조각에서 처리한 일부 결과를 저장할 공간과 일부 결과를 합쳐서 저장할 공간이 각각 필요합니다.\n",
        "\n",
        "이 저장 공간은 전체 시스템에 모두 접근이 가능하고요, 방대한 양의 데이터를 저장할 수 있어야하고 하둡에서는 이 공간으로 HDFS를 사용합니다."
      ],
      "metadata": {
        "id": "nSvhDgY_tVBF"
      }
    }
  ]
}