{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCYmF7cqhYpY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEyFIslJa08N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "label_df=pd.read_csv('/content/drive/MyDrive/seoul/train.csv')\n",
        "label_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cQmKvJ5hTQf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def get_train_data(data_dir):\n",
        "  img_path_list=[]\n",
        "  label_list=[]\n",
        "\n",
        "  # get image path\n",
        "  img_path_list.extend(glob(os.path.join(data_dir,'*.PNG')))\n",
        "  img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
        "\n",
        "  # get label\n",
        "  label_list.extend(label_df['label'])\n",
        "\n",
        "  return img_path_list,label_list\n",
        "\n",
        "def get_test_data(data_dir):\n",
        "  img_path_list=[]\n",
        "\n",
        "  # get image path\n",
        "  img_path_list.extend(glob(os.path.join(data_dir,'*.PNG')))\n",
        "  img_path_list.sort(key= lambda x:int(x.split('/')[-1].split('.')[0]))\n",
        "  print(img_path_list)\n",
        "\n",
        "  return img_path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5nZsjZehZHD"
      },
      "outputs": [],
      "source": [
        "label_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqtICbrWhr79"
      },
      "outputs": [],
      "source": [
        "all_img_path,all_label=get_train_data('/content/drive/MyDrive/seoul/train')\n",
        "test_img_path=get_test_data('/content/drive/MyDrive/seoul/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-xl9l2jh0H9"
      },
      "outputs": [],
      "source": [
        "all_label[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpSwjMTdh3hT"
      },
      "outputs": [],
      "source": [
        "all_img_path[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgSppnrh4xf"
      },
      "outputs": [],
      "source": [
        "test_img_path[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOGDOb93h8W5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WRyd9yth9mb"
      },
      "outputs": [],
      "source": [
        "#GPU 체크 및 할당\n",
        "if torch.cuda.is_available():    \n",
        "    #device = torch.device(\"cuda:0\")\n",
        "    print('Device:', device)\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMWPpl7Hh_iK"
      },
      "outputs": [],
      "source": [
        "#하이퍼 파라미터 튜닝\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':128, #이미지 사이즈\n",
        "    'EPOCHS':60, #에포크\n",
        "    'LEARNING_RATE':2e-2, #학습률\n",
        "    'BATCH_SIZE':32, #배치사이즈\n",
        "    'SEED':41, #시드\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nggnf-00iJb1"
      },
      "source": [
        "\n",
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O_q3PoAiBCZ"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKoc2fnxiMzK"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,img_path_list,label_list,train_mode=True,transforms=None): #필요한 변수들을 선언\n",
        "    self.transforms=transforms\n",
        "    self.train_mode=train_mode\n",
        "    self.img_path_list=img_path_list\n",
        "    self.label_list=label_list\n",
        "\n",
        "  def __getitem__(self,index):  # index 번쨰 data를 return\n",
        "    img_path=self.img_path_list[index]\n",
        "    image=cv2.imread(img_path)\n",
        "    if self.transforms is not None:\n",
        "      image=self.transforms(image)\n",
        "\n",
        "    if self.train_mode:\n",
        "      label=self.label_list[index]\n",
        "      return image,label\n",
        "\n",
        "    else:\n",
        "      return image\n",
        "    \n",
        "  def __len__ (self):\n",
        "    return len(self.img_path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8aNSMsKiOlc"
      },
      "outputs": [],
      "source": [
        "tempdataset=CustomDataset(all_img_path,all_label,train_mode=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(tempdataset.__getitem__(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sCJRqFqir_B"
      },
      "outputs": [],
      "source": [
        "tempdataset[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBH0HXhait63"
      },
      "outputs": [],
      "source": [
        "train_len=(int(len(all_img_path) * 0.75))\n",
        "val_len=int(len(all_img_path) * 0.25)\n",
        "\n",
        "train_img_path=all_img_path[:train_len]\n",
        "train_label=all_label[:train_len]\n",
        "\n",
        "vali_img_path=all_img_path[train_len:]\n",
        "vali_label=all_label[train_len:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4SFiz35iwFf"
      },
      "outputs": [],
      "source": [
        "print(train_len)\n",
        "print(val_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c00tuxbPiwfe"
      },
      "outputs": [],
      "source": [
        "train_transform=transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Numpy 배열에서 PIL 이미지로\n",
        "    transforms.Resize([CFG['IMG_SIZE'],CFG['IMG_SIZE']]), # 이미지 사이즈 변형\n",
        "    transforms.ToTensor(), # 이미지 데이터를 tensor\n",
        "    transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)), # 이미지 정규화\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "    ])\n",
        "\n",
        "test_transform=transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize([CFG['IMG_SIZE'],CFG['IMG_SIZE']]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZNPbYzNi8fd"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Dataloader class는 bath기반의 딥러닝모델 학습을 위해서 mini batch를 만들어주는 역할을 한다\n",
        "\n",
        "dataloader를 통해 dataset의 전체 데이터가 batch size로 나뉘게 된다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcmMwe5ciwhv"
      },
      "outputs": [],
      "source": [
        "# Get Dataloader\n",
        "\n",
        "# CustomDataset class를 통하여 train dataset생성\n",
        "train_dataset=CustomDataset(train_img_path, train_label,train_mode=True,transforms=train_transform)\n",
        "# 만든 train dataset를 DataLoader에 넣어 batch 만들기\n",
        "train_loader=DataLoader(train_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=True,num_workers=0)\n",
        "\n",
        "# validation도 적용\n",
        "vali_dataset=CustomDataset(vali_img_path,vali_label,train_mode=True,transforms=test_transform)\n",
        "vali_loader=DataLoader(vali_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=False,num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LhEMNyXiwl2"
      },
      "outputs": [],
      "source": [
        "train_batches=len(train_loader)\n",
        "vali_batches=len(vali_loader)\n",
        "\n",
        "print('total train imgs:',train_len,'/ total train bathcnes:', train_batches)\n",
        "print('total valid imgs:',val_len,'/ total valid batches:', vali_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ePcZOGgjU72"
      },
      "source": [
        "### model\n",
        "\n",
        "모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4wHpLh1iwog"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model,optimizer,train_loader,scheduler,device):\n",
        "  model.to(device)\n",
        "  n=len(train_loader)\n",
        "  best_loss=10000\n",
        "\n",
        "  for epoch in range(1,CFG['EPOCHS']+1):  # 에포크 설정\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "\n",
        "    for img,label in tqdm(iter(train_loader)):\n",
        "      img,label=img.to(device),label.to(device)\n",
        "      optimizer.zero_grad() # 배치마다 optimzier 초기화\n",
        "\n",
        "      logit=model(img)\n",
        "      loss=criterion(logit,label)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step() # 가중치 최적화\n",
        "      running_loss+=loss.item()\n",
        "\n",
        "    print('[%d] Train loss: %.10f' %(epoch, running_loss/len(train_loader)))\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    # validation set 평가\n",
        "    model.eval() # evaluatoin 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
        "    vali_loss=0.0\n",
        "    correct=0\n",
        "\n",
        "    with torch.no_grad(): # 파라미터 업데이트 안하기 때문에 no_grad 사용\n",
        "      for img,label in tqdm(iter(vali_loader)):\n",
        "        img,label=img.to(device),label.to(device)\n",
        "\n",
        "        logit=model(img)\n",
        "        vali_loss+= criterion(logit,label)\n",
        "        pred=logit.argmax(dim=1,keepdim=True)  # 10개의 class 중 가장 값이 높은 것을 예측 label로 추출\n",
        "        correct += pred.eq(label.view_as(pred)).sum().item()  # 예측값과 실제값이 맞으면 1 아니면 0으로 합산\n",
        "    vali_acc=100 * correct/len(vali_loader.dataset)\n",
        "\n",
        "    print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.0f}%)\\n'.format(vali_loss / len(vali_loader), correct, len(vali_loader.dataset), 100 * correct / len(vali_loader.dataset)))\n",
        "    \n",
        "    if best_loss > vali_loss:\n",
        "      best_loss=vali_loss\n",
        "      torch.save(model.state_dict(),'/content/best_model.pth')\n",
        "      print('Model Saved')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPWAFGXBjbtu"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "resnet=models.resnet50(pretrained=True).to(device)\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "in_features=resnet.fc.in_features\n",
        "\n",
        "classifier=nn.Sequential(\n",
        "    nn.Linear(in_features,1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(1024,10),\n",
        "\n",
        ")\n",
        "\n",
        "resnet.fc=classifier\n",
        "\n",
        "\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(params=resnet.parameters(),lr=CFG['LEARNING_RATE'])\n",
        "scheduler=None\n",
        "\n",
        "resnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-cG9ObXjevd"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(resnet,(3,128,128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPhrDTFUjiJN"
      },
      "outputs": [],
      "source": [
        "train(resnet, optimizer, train_loader, scheduler, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wms6d9DYjix8"
      },
      "outputs": [],
      "source": [
        "def predict(model,test_loader,device):\n",
        "  model.eval()\n",
        "  model_pred=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for img in tqdm(iter(test_loader)):\n",
        "      img=img.to(device)\n",
        "\n",
        "      pred_logit=model(img)\n",
        "      pred_logit=pred_logit.argmax(dim=1,keepdim=True).squeeze(1)\n",
        "      model_pred.extend(pred_logit.tolist())\n",
        "  return model_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDoGQijrjpCU"
      },
      "outputs": [],
      "source": [
        "test_dataset=CustomDataset(test_img_path,None,train_mode=False,transforms=test_transform)\n",
        "test_loader=DataLoader(test_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=False,num_workers=0)\n",
        "\n",
        "checkpoint=torch.load('/content/best_model.pth')\n",
        "Predictor=resnet.to(device)\n",
        "Predictor.load_state_dict(checkpoint)\n",
        "\n",
        "preds=predict(Predictor,test_loader,device)\n",
        "preds[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MI-daIhjrUg"
      },
      "outputs": [],
      "source": [
        "submission=pd.read_csv('/content/drive/MyDrive/seoul/sample_submission.csv')\n",
        "submission['label']=preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reudVK5Mjs1Y"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('/content/submission_resnet50_2.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMs0xGuenM5c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SEOUL_LANDMARK",
      "provenance": [],
      "authorship_tag": "ABX9TyOvHn8Gfw00zpj//2dLdUwK"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}